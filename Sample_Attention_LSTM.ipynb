{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tsfresh import extract_features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from Model import Sample_Attention_LSTM\n",
    "from data import Sample_Attention_LSTM_dataset\n",
    "from train import train\n",
    "from torch.utils.data import DataLoader\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('C:/Users/Administrator/Desktop/科研/github/Data/202209高压用户出账电量.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = df[\"户号\"]\n",
    "df_ht = df[\"合同容量\"]\n",
    "df_yx = df[\"运行容量\"]\n",
    "df_ek = df[\"用电类别\"]\n",
    "df_level = df[\"电压等级\"]\n",
    "df_pm = df[\"电价码\"]\n",
    "df_ld = df[\"临电标志\"]\n",
    "df_val = df.iloc[:,23:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one_hot\n",
    "df_ek = pd.get_dummies(df_ek)\n",
    "df_level = pd.get_dummies(df_level)\n",
    "df_pm = pd.get_dummies(df_pm)\n",
    "df_ld = pd.get_dummies(df_ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#统计指标抽取\n",
    "df_val = df_val.fillna(0)\n",
    "ts_data = df_val.stack().reset_index()\n",
    "ts_data.columns = ['id', 'time', 'value']\n",
    "# 使用 tsfresh 抽取特征\n",
    "extracted_features = extract_features(ts_data, column_id='id', column_sort='time', column_value='value')\n",
    "# extracted_features = df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_data 维度(7882, 1022)\n",
    "combined_data = pd.concat([df_val, extracted_features,df_ek,df_level,df_pm,df_ld,df_ht,df_yx], axis=1)\n",
    "combined_data = combined_data.fillna(0)\n",
    "# 创建 StandardScaler 实例\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 使用 StandardScaler 对 combined_data 进行标准化\n",
    "standardized_data = pd.DataFrame(scaler.fit_transform(combined_data), columns=combined_data.columns)\n",
    "# 应用 PCA 降维\n",
    "pca = PCA(n_components=0.5)\n",
    "reduced_features = pca.fit_transform(standardized_data)\n",
    "# 显示结果\n",
    "print(\"抽取统计特征之后的特征数：\", standardized_data.shape[1])\n",
    "print(\"降维后的特征数：\", reduced_features.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置要尝试的聚类数目范围\n",
    "cluster_range = range(2, 11)\n",
    "\n",
    "# 用于存储每个聚类数目的轮廓系数和簇内误方差\n",
    "silhouette_scores = []\n",
    "inertias = []\n",
    "\n",
    "# 对于每个聚类数目，进行k-means++聚类并计算轮廓系数和簇内误方差\n",
    "for n_clusters in cluster_range:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, init='k-means++', random_state=42)\n",
    "    kmeans.fit(reduced_features)\n",
    "    labels = kmeans.labels_\n",
    "    silhouette_scores.append(silhouette_score(reduced_features, labels))\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "# 绘制轮廓系数图 轮廓系数处于[-1,1]之间，越高越好\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(cluster_range, silhouette_scores, marker='o', linewidth=2)\n",
    "plt.xlabel(\"Number of clusters\", fontsize=14)\n",
    "plt.ylabel(\"Silhouette Score\", fontsize=14)\n",
    "plt.title(\"Silhouette Score vs Number of Clusters\", fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 绘制簇内误方差图 找肘部点，即误差下降速度突然减缓的点，这个点通常代表了一个合适数目的聚类\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(cluster_range, inertias, marker='o', linewidth=2)\n",
    "plt.xlabel(\"Number of clusters\", fontsize=14)\n",
    "plt.ylabel(\"Inertia\", fontsize=14)\n",
    "plt.title(\"Inertia vs Number of Clusters\", fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#由上图可以看出，适合聚3类\n",
    "kmeans = KMeans(n_clusters=3, init='k-means++', random_state=42)\n",
    "kmeans.fit(reduced_features)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保 df_id 和 labels 的长度相同\n",
    "assert len(df_id) == len(labels), \"Lengths of df_id and labels do not match.\"\n",
    "\n",
    "# 创建一个新的 DataFrame，将 df_id 转换为 DataFrame\n",
    "df_id_df = pd.DataFrame({'id': df_id.values})\n",
    "\n",
    "# 将聚类标签添加到新的 DataFrame\n",
    "df_id_df['cluster'] = labels\n",
    "\n",
    "# 重置索引\n",
    "df_id_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 按照 cluster 标签将用户分组\n",
    "cluster_0 = df_id_df[df_id_df['cluster'] == 0]\n",
    "cluster_1 = df_id_df[df_id_df['cluster'] == 1]\n",
    "cluster_2 = df_id_df[df_id_df['cluster'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id_val = pd.concat([df_id,df_val],axis=1)\n",
    "# 从原始 DataFrame 中获取 cluster_0 的数据\n",
    "cluster_0_data = df_id_val[df_id_val['户号'].isin(cluster_0['id'])]\n",
    "\n",
    "# 从原始 DataFrame 中获取 cluster_1 的数据\n",
    "cluster_1_data = df_id_val[df_id_val['户号'].isin(cluster_1['id'])]\n",
    "\n",
    "# 从原始 DataFrame 中获取 cluster_2 的数据\n",
    "cluster_2_data = df_id_val[df_id_val['户号'].isin(cluster_2['id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_indices = list(range(1, 138, 2))\n",
    "cluster_0_sum = cluster_0_data.iloc[:,odd_indices].sum(axis=0)\n",
    "cluster_0_sum = cluster_0_sum.to_numpy()\n",
    "\n",
    "cluster_1_sum = cluster_1_data.iloc[:,odd_indices].sum(axis=0)\n",
    "cluster_1_sum = cluster_1_sum.to_numpy()\n",
    "\n",
    "cluster_2_sum = cluster_2_data.iloc[:,odd_indices].sum(axis=0)\n",
    "cluster_2_sum = cluster_2_sum.to_numpy()\n",
    "cluster_2_sum = torch.tensor(cluster_2_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#选择最后一类的数据作为样例\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(cluster_2_sum)\n",
    "plt.title(\"Cluster 2 sum Curve\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"sum\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 12\n",
    "horizon_size = 1\n",
    "\n",
    "train_data = cluster_2_sum[0:50]\n",
    "test_data = cluster_2_sum[50:]\n",
    "\n",
    "# 计算张量的均值和标准差\n",
    "mean = train_data.mean(dim=0)\n",
    "std = train_data.std(dim=0)\n",
    "# 对张量进行标准化\n",
    "train_data = (train_data - mean) / std\n",
    "\n",
    "attention_key = []\n",
    "for i in range(0,len(train_data)-seq_len-horizon_size):\n",
    "    input_seq = train_data[i:i+seq_len]\n",
    "    attention_key.append(input_seq)\n",
    "attention_key = torch.stack(attention_key)\n",
    "\n",
    "attention_value = []\n",
    "for i in range(0,len(train_data)-seq_len-horizon_size):\n",
    "    input_value = train_data[i:i+seq_len+horizon_size]\n",
    "    attention_value.append(input_value)\n",
    "attention_value = torch.stack(attention_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入模型\n",
    "config = {\n",
    "    'horizon_size':1,\n",
    "    'hidden_size':8,#8\n",
    "    'dropout': 1e-1,\n",
    "    'layer_size':1,\n",
    "    'lr': 1e-2,#5\n",
    "    'batch_size': 10,\n",
    "    'num_epochs':60,\n",
    "    'L1':4,\n",
    "    'L2':2,\n",
    "    'seq_len':12,\n",
    "    \n",
    "}\n",
    "horizon_size = config['horizon_size']\n",
    "hidden_size = config['hidden_size']\n",
    "dropout = config['dropout']\n",
    "layer_size = config['layer_size']\n",
    "seq_len = config['seq_len']\n",
    "lr = config['lr']\n",
    "batch_size = config['batch_size']\n",
    "num_epochs = config['num_epochs']\n",
    "L1 = config['L1']\n",
    "L2 = config['L2']\n",
    "\n",
    "myseed = 6666  # set a random seed for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(myseed)\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(myseed)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "dataset = Sample_Attention_LSTM_dataset(train_data,horizon_size,seq_len)\n",
    "model = Sample_Attention_LSTM(horizon_size,seq_len,dropout,layer_size,L1,L2,hidden_size,device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model,dataset,lr,batch_size,num_epochs,attention_key,attention_value,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘制拟合曲线\n",
    "sample_nums = len(train_data)-horizon_size-seq_len\n",
    "data_iter = DataLoader(dataset=dataset, batch_size=sample_nums, shuffle=False,num_workers=0)\n",
    "for (sample_input,sample_vals) in data_iter:\n",
    "    fit_seq = model.predict(sample_input,attention_key=attention_key,attention_value=attention_value)\n",
    "    fit_seq = fit_seq * std.reshape(-1, 1) + mean.reshape(-1, 1)\n",
    "    sample_vals = sample_vals * std.reshape(-1, 1) + mean.reshape(-1, 1)\n",
    "    plt.plot(fit_seq,color = '#1f77b4',label='fit_seq')\n",
    "    plt.plot(sample_vals, color = '#d62728',label='real_val')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘制测试集预测曲线\n",
    "# 对张量进行标准化\n",
    "test_mean = test_data.mean(dim=0)\n",
    "test_std = test_data.std(dim=0)\n",
    "test_data_n = (test_data - test_mean) / test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Sample_Attention_LSTM_dataset(test_data_n,horizon_size,seq_len)\n",
    "test_sample_nums = len(test_data_n)-seq_len-horizon_size\n",
    "test_data_iter = DataLoader(dataset=test_dataset, batch_size=test_sample_nums, shuffle=False,num_workers=0)\n",
    "for (test_input,test_real_vals) in test_data_iter:\n",
    "    print(test_input.shape)\n",
    "    test_seq = model.predict(test_input,attention_key=attention_key,attention_value=attention_value)\n",
    "    print(test_seq.shape)\n",
    "    test_seq = test_seq * test_std.reshape(-1, 1) + test_mean.reshape(-1, 1)\n",
    "    test_real_vals = test_real_vals * test_std.reshape(-1, 1) + test_mean.reshape(-1, 1)\n",
    "    plt.plot(test_seq,color = '#1f77b4',label='predict_seq')\n",
    "    plt.plot(test_real_vals, color = '#d62728',label='real_val')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#可以看到，效果还是很不错的，就是有一个异常点误差比较大34%\n",
    "#经过历史数据的查询，发现该时间点对应的是2022年4月，正好是疫情影响最严重的时间，与2021年相比，下挫了25%\n",
    "#如果按照正常规律发展，应该比往年略微有所上升\n",
    "#因此，如果不考虑疫情的影响，该点误差应该会落在10%以内\n",
    "#总误差2.67%\n",
    "mape = (test_real_vals - test_seq)/test_real_vals\n",
    "print(mape)\n",
    "s_mape = (sum(test_real_vals) - sum(test_seq))/sum(test_real_vals)\n",
    "print(s_mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_real_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(x=np.arange(len(mape)), y=np.array(mape).reshape(-1), marker='o', markersize=10, linewidth=2)\n",
    "plt.xlabel('data points', fontsize=14)\n",
    "plt.ylabel('MAPE', fontsize=14)\n",
    "plt.title('Image of MAPE', fontsize=16)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.16 ('pytorch_train')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8fbad53655fe38d5ab9f5473cfbc3673770f1f34c5099a69c56f611760569131"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
